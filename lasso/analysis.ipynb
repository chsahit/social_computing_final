{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from langdetect import detect_langs\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Bag-of-word Vectors for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all words that either identify \"male\" or \"female\"\n",
    "def get_gendered_words():\n",
    "    vocab10K=pd.read_csv(\"../vocab10K.csv\")\n",
    "    male = vocab10K.loc[vocab10K['female'] == 0,:]\n",
    "    male = male['word'].tolist()\n",
    "    female = vocab10K.loc[vocab10K['female'] == 1,:]\n",
    "    female = female['word'].tolist()\n",
    "    return male, female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes either \"twitter\" or \"reddit\" as a parameter.\n",
    "# Goes through each post and identifies the one using only male words as male\n",
    "# and female words as female.  \n",
    "# returns a list of unambiguous posts and a vector of male (0) and female (1) words\n",
    "def identify_gendered_posts(male, female, platform = \"twitter\"):\n",
    "    path = \"../custom_data/all_tweets.csv\"\n",
    "    if platform == \"reddit\":\n",
    "        path = \"../custom_data/economics_posts.csv\"\n",
    "    data = pd.read_csv(path)\n",
    "    vocab = pd.read_csv(\"../vocab10K.csv\")\n",
    "    num_entries = data.shape[0]\n",
    "    y = list()\n",
    "    male_set = set(male)\n",
    "    female_set = set(female)\n",
    "    nFemale = 0\n",
    "    nMale = 0\n",
    "    unambiguous_posts = list()\n",
    "    for i in range(num_entries):\n",
    "        if i % 1000 == 0:\n",
    "            print(str(i) + \" posts scanned\")\n",
    "        post = str(data['text'][i]).lower()\n",
    "        lang = \"en\"\n",
    "        try:\n",
    "            lang = str(detect_langs(post))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        if \"en\" not in lang:\n",
    "            continue\n",
    "        i_male, i_female = 0, 0\n",
    "        for word in post.split():\n",
    "            if word in male_set:\n",
    "                i_male += 1\n",
    "            elif word in female_set:\n",
    "                i_female += 1\n",
    "        if i_male > 0 and i_female == 0:\n",
    "            y.append(0)\n",
    "            nMale += 1\n",
    "            unambiguous_posts.append(post)\n",
    "        if i_female > 0 and i_male == 0:\n",
    "            y.append(1)\n",
    "            nFemale += 1\n",
    "            unambiguous_posts.append(post)\n",
    "    print(\"nMale: \", nMale)\n",
    "    print(\"nFemale: \", nFemale)\n",
    "    return unambiguous_posts, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a matrix of unambiguous posts to a bag of words. \n",
    "# Saves the bow and labels to a text file corresponding to the platform\n",
    "def build_bow(unambiguous_posts, y, platform = \"twitter\"):\n",
    "    stopword = set(stopwords.words('english'))\n",
    "    vocab = pd.read_csv(\"../vocab10K.csv\")\n",
    "    num_entries = len(unambiguous_posts)\n",
    "    X = np.zeros((num_entries, 10000))\n",
    "    vocab_list = vocab['word'].tolist()\n",
    "    vocab_set = set(vocab_list)\n",
    "    for i in range(num_entries):\n",
    "        if i % 100 == 0:\n",
    "            print(str(i) + \" rows populated\")\n",
    "        post = unambiguous_posts[i].split()\n",
    "        for word in post:\n",
    "            if word in vocab_set and word not in stopword:\n",
    "                idx = vocab_list.index(word)\n",
    "                X[i, idx] = 1\n",
    "    if platform == \"twitter\":\n",
    "        np.save(\"twitter_data\", X)\n",
    "        np.save(\"twitter_labels\", y)\n",
    "    elif platform == \"reddit\":\n",
    "        np.save(\"reddit_data\", X)\n",
    "        np.save(\"reddit_labels\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a LASSO model on the BOW and labels and analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train lasso function defined in lasso.py\n",
    "import lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the coefficients learned from lasso and extracts which words were the most predictive\n",
    "def get_top_words_from_model(platform = \"twitter\"):\n",
    "    vocablist = pd.read_csv(\"../vocab10K.csv\")\n",
    "    coeffs = np.loadtxt(\"../coef_twitter.txt\")\n",
    "    if platform == \"reddit\":\n",
    "        coeffs = np.loadtxt(\"../coef_reddit.txt\")\n",
    "    women_words = coeffs.argsort()[-15:][::-1]\n",
    "    men_words = coeffs.argsort()[:15]\n",
    "    # look at which words correspond to the most important coeff\n",
    "    word_map = np.loadtxt(\"../i_keep_columns.txt\")\n",
    "    women_indices = word_map[women_words] + 1\n",
    "    men_indices = word_map[men_words] + 1\n",
    "    print(\"women: \")\n",
    "    print(vocablist.loc[vocablist['index'].isin(women_indices)]['word'])\n",
    "    print(\"men: \")\n",
    "    print(vocablist.loc[vocablist['index'].isin(men_indices)]['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n",
      "full X:  (1596, 10000)\n",
      "train x before:  (1436, 9540)\n",
      "train y:  (1436,)\n",
      "test:  (160, 9540)\n",
      "train x:  (1436, 2000)\n",
      "train y:  (1436,)\n",
      "test:  (160, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.5s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.488627873875387\n",
      "running analysis\n",
      "women: \n",
      "282         higher\n",
      "347           tell\n",
      "352            let\n",
      "436      including\n",
      "463          macro\n",
      "480          black\n",
      "483         please\n",
      "486        support\n",
      "551           list\n",
      "580        talking\n",
      "665           stay\n",
      "667          share\n",
      "877     colleagues\n",
      "922         gender\n",
      "1724        listen\n",
      "Name: word, dtype: object\n",
      "men: \n",
      "58              |\n",
      "151           new\n",
      "187          back\n",
      "207        theory\n",
      "261        always\n",
      "292        others\n",
      "333      interest\n",
      "383           yet\n",
      "475     professor\n",
      "515       harvard\n",
      "532          mind\n",
      "682       reading\n",
      "966        modern\n",
      "979         death\n",
      "1368        views\n",
      "Name: word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# running everything in unison\n",
    "import importlib\n",
    "importlib.reload(lasso)\n",
    "platform = \"twitter\"\n",
    "'''print(\"identifying gendered words\")\n",
    "male, female = get_gendered_words()\n",
    "print(\"identifying gendered posts\")\n",
    "unambiguous_posts, y = identify_gendered_posts(male, female,  platform = platform)\n",
    "print(\"building bag of words\")\n",
    "build_bow(unambiguous_posts, y, platform = platform)'''\n",
    "print(\"training model\")\n",
    "lasso.train_lasso(platform = platform, shrink = True)\n",
    "print(\"running analysis\")\n",
    "get_top_words_from_model(platform = platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count instances of word \"Yellen\" (case-insensitive)\n",
    "import pandas as pd\n",
    "vocab = pd.read_csv(\"../gendered_posts.csv\")\n",
    "list_of_posts = vocab['raw_post'].tolist()\n",
    "y_count = 0\n",
    "for post in list_of_posts:\n",
    "    p = post.lower()\n",
    "    if \"yellen\" in p:\n",
    "        y_count += 1\n",
    "print(y_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduction of Wu's results:\n",
    "# (1) get most important coeffs from lasso-logit-full\n",
    "coeffs = np.loadtxt(\"../coef_lasso_logit_full.txt\")\n",
    "top_words = coeffs.argsort()[-10:][::-1]\n",
    "print(coeffs[top_words])\n",
    "# (2) look at which words correspond to the most important coeff\n",
    "vocablist = pd.read_csv(\"../vocab10K.csv\")\n",
    "word_map = np.loadtxt(\"../i_keep_columns.txt\")\n",
    "vocab_indices = word_map[top_words] + 1\n",
    "print(vocablist.loc[vocablist['index'].isin(vocab_indices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
