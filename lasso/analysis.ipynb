{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.88317862 2.20474637 1.89043858 1.88126299 1.84982683 1.77917599\n",
      " 1.74436485 1.67609757 1.64098876 1.55399143]\n"
     ]
    }
   ],
   "source": [
    "# get most important coeffs from lasso-logit-full\n",
    "coeffs = np.loadtxt(\"../coef_lasso_logit_full.txt\")\n",
    "top_words = coeffs.argsort()[-10:][::-1]\n",
    "print(coeffs[top_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index        word  female  i_pronoun  exclude      coef        ME  \\\n",
      "1106   1107         hot     NaN        NaN      NaN  1.849972  0.271002   \n",
      "1530   1531   beautiful     NaN        NaN      NaN  1.637034  0.239809   \n",
      "1696   1697  attractive     NaN        NaN      NaN  1.672941  0.245069   \n",
      "3298   3299       marry     NaN        NaN      NaN  1.879690  0.275356   \n",
      "4135   4136    pregnant     NaN        NaN      NaN  2.203002  0.322718   \n",
      "5067   5068   pregnancy     NaN        NaN      NaN  1.734884  0.254143   \n",
      "7146   7147    marrying     NaN        NaN      NaN  1.775510  0.260094   \n",
      "7889   7890      breast     NaN        NaN      NaN  1.546361  0.226526   \n",
      "8914   8915      hotter     NaN        NaN      NaN  2.882882  0.422313   \n",
      "9137   9138        plow     NaN        NaN      NaN  1.892775  0.277273   \n",
      "\n",
      "      nFemale  nMale  coef_pronoun  ME_pronoun  nFemale_pronoun  \\\n",
      "1106     3613   1053      1.220669    0.197421             1309   \n",
      "1530     1419    610      0.925590    0.149697              524   \n",
      "1696     1578    417      1.120419    0.181208              547   \n",
      "3298     1287    258      1.281486    0.207257              557   \n",
      "4135      564    120      1.597201    0.258318              270   \n",
      "5067      202     61      1.807278    0.292295              106   \n",
      "7146      262     49      1.222155    0.197662              117   \n",
      "7889      134     48      1.361359    0.220175               62   \n",
      "8914      307     31      1.789012    0.289340              120   \n",
      "9137      274     83      1.354111    0.219003              146   \n",
      "\n",
      "      nMale_pronoun  linear_coef  \n",
      "1106            658     0.215589  \n",
      "1530            346     0.136367  \n",
      "1696            246     0.189988  \n",
      "3298            191     0.225843  \n",
      "4135             98     0.239631  \n",
      "5067             27     0.172747  \n",
      "7146             34     0.058259  \n",
      "7889             30     0.055059  \n",
      "8914             31     0.203085  \n",
      "9137             60     0.244884  \n"
     ]
    }
   ],
   "source": [
    "# look at which words correspond to the most important coeff\n",
    "vocablist = pd.read_csv(\"../vocab10K.csv\")\n",
    "word_map = np.loadtxt(\"../i_keep_columns.txt\")\n",
    "vocab_indices = word_map[top_words] + 1\n",
    "print(vocablist.loc[vocablist['index'].isin(vocab_indices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'his', 'him', 'guy', 'man', 'men', 'guys', \"he's\", 'bros', 'bro', 'male', 'himself', 'john', 'krugman', 'paul', 'david', 'father', 'son', 'friedman', 'mark', 'michael', 'robert', 'george', 'joe', 'boy', 'dude', 'james', 'piketty', 'husband', 'boys', 'peter', 'males', 'thomas', 'mankiw', 'lucas', 'brother', 'heckman', 'dad', 'cochrane', 'marx', 'keynes', 'christopher', 'bob', 'stiglitz', 'brothers', 'noah', 'summers', 'adam', 'richard', 'nash', 'acemoglu', 'steve', 'sir', 'martin', 'elsevier', 'simon', \"he'll\", \"he'd\", 'jonathan', 'samuelson', 'roberts', 'larry', 'frey', 'ryan', 'prescott', 'jack', 'milton', 'tom', 'levitt', 'eric', 'william', 'walters', 'boyfriend', 'hayek', 'hansen', 'daniel', 'ben', 'chris', 'becker', 'fama', 'joseph', 'andrew', 'tirole', 'arrow', 'matthew', 'frank', 'keen', 'gary', 'dudes', 'shleifer', 'greg', 'bernanke', 'sargent', 'fathers', 'tim', 'stephen', 'ted', 'wolfers', 'sons', 'roth', 'jackson', 'justin', 'chetty', 'steven', 'alan', 'phil', 'warren', 'barro', \"men's\", 'kruggles', 'wooldridge', 'fisher', \"man's\", 'daddy', 'kevin', 'alexander', 'edward', 'miller', 'matt', 'russ', 'cowen', 'phillips', 'mike', 'neumann', 'pat', 'pathak', 'robinson', 'ravikumar', 'woodford', 'saez', 'williamson', 'gentleman', 'rogoff', 'ricardo', 'benjamin', 'ken', 'blanchard', 'campbell', 'brian', 'uncle', 'shiller', 'patrick', 'moore', 'gordon', \"krugman's\", 'allen', 'bf', 'frisch', 'roger', 'raj', 'sam', 'jeremy', 'harry', 'delong', 'henry', 'parag', \"friedman's\", 'carlos', 'ron', 'sims', 'angrist', 'lacour', \"piketty's\", 'karl', 'rubin', 'thaler', 'jeff', 'werning', 'brady', 'charlie', 'nick', 'daron', 'jose', 'walker', 'deaton', 'nicholas', 'murphy', 'shapiro', 'krueger', 'kehoe', 'jeffrey', \"guy's\", 'kenneth', 'rabin', 'rick', 'evans', 'philip', 'jason', 'terry', 'hayashi', 'jimmy', 'carl', 'albert', 'husbands', 'colin', 'baker', 'rust', 'debreu', 'levine', 'borjas', 'jon', 'chomsky', 'greene', 'calvo', 'walter', 'wallace', 'gintis', 'epstein', 'tony', 'henderson', 'powell', 'antonio', 'berry', 'adams', 'pierre', 'rubinstein', 'graham', 'euler', 'gregory', 'perez', 'papa', 'jay', 'autor', 'imbens', 'lars', 'bertrand', 'victor', 'eugene', 'grandfather', 'akerlof', 'myerson', 'craig', 'arthur', 'duffie', 'harvey', 'glaeser']\n"
     ]
    }
   ],
   "source": [
    "# HELPER: dump all the gender coded words into a file\n",
    "vocab10K=pd.read_csv(\"../vocab10K.csv\")\n",
    "male = vocab10K.loc[vocab10K['female'] == 0,:]\n",
    "male = male['word'].tolist()\n",
    "female = vocab10K.loc[vocab10K['female'] == 1,:]\n",
    "female = female['word'].tolist()\n",
    "print(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "nMale:  2204\n",
      "nFemale:  324\n"
     ]
    }
   ],
   "source": [
    "# HELPER: label data\n",
    "#path = \"../custom_data/all_tweets.csv\"\n",
    "path = \"../custom_data/economics_posts.csv\"\n",
    "data = pd.read_csv(path)\n",
    "vocab = pd.read_csv(\"../vocab10K.csv\")\n",
    "#print(data['text'])\n",
    "num_entries = data.shape[0]\n",
    "ys = list()\n",
    "male_set = set(male)\n",
    "female_set = set(female)\n",
    "nFemale = 0\n",
    "nMale = 0\n",
    "unambiguous_posts = list()\n",
    "for i in range(num_entries):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    post = str(data['text'][i]).lower()\n",
    "    #print(post)\n",
    "    i_male, i_female = 0, 0\n",
    "    for word in post.split():\n",
    "        if word in male_set:\n",
    "            i_male += 1\n",
    "            #print(\"male: \", word)\n",
    "        elif word in female_set:\n",
    "            i_female += 1\n",
    "            #print(\"female: \", word)\n",
    "    if i_male > i_female:\n",
    "        ys.append(0)\n",
    "        nMale += 1\n",
    "        unambiguous_posts.append(post)\n",
    "    if i_female > i_male:\n",
    "        ys.append(1)\n",
    "        nFemale += 1\n",
    "        unambiguous_posts.append(post)\n",
    "print(\"nMale: \", nMale)\n",
    "print(\"nFemale: \", nFemale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "# Helper: make bow\n",
    "vocab = pd.read_csv(\"../vocab10K.csv\")\n",
    "num_entries = len(unambiguous_posts)\n",
    "X = np.zeros((num_entries, 10000))\n",
    "vocab_list = vocab['word'].tolist()\n",
    "vocab_set = set(vocab_list)\n",
    "for i in range(num_entries):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    post = unambiguous_posts[i].split()\n",
    "    for word in post:\n",
    "        if word in vocab_set:\n",
    "            X[i, vocab_list.index(word)] = 1\n",
    "\n",
    "np.save(\"reddit_data\", X)\n",
    "np.save(\"reddit_labels\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
